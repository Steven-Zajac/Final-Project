{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa8f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/generating-modern-arts-using-generative-adversarial-network-gan-on-spell-39f67f83c7b4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dd17e2",
   "metadata": {},
   "source": [
    "### In order for our GAN model to work adequately, we must resize all the images that we will be feeding it to the same size. 128x128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1626ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing...\n",
      "saving file...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Define an image size and image channel\n",
    "# Resize all to 128X128 and since coloured, channels is set to 3 (RBG)\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "IMAGE_CHANNELS = 3\n",
    "IMAGE_DIR = 'Artsies/wikiart/Baroque/'\n",
    "\n",
    "#Define the image dir path\n",
    "\n",
    "image_path = IMAGE_DIR\n",
    "\n",
    "training_data = []\n",
    "\n",
    "# Iterating over the images inside the directory and resizing them using Pillow's resize method\n",
    "print('resizing...')\n",
    "\n",
    "# Pillow to reszie and appending them to a list as np array\n",
    "for filename in os.listdir(image_path):\n",
    "    path = os.path.join(image_path,filename)\n",
    "    image = Image.open(path).resize((IMAGE_SIZE,IMAGE_SIZE), Image.ANTIALIAS)    \n",
    "    training_data.append(np.asarray(image))\n",
    "    \n",
    "    \n",
    "#Use np to reshape the array in a suitable formate and normalizing the data \n",
    "training_data = np.reshape(training_data, (-1, IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "training_data = training_data / 127.5 -1\n",
    "\n",
    "print('saving file...')\n",
    "np.save('baroque_data.npy', training_data) # save the image array as npy binary file \n",
    "# Prevents us from going through all the images every time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ea6d72",
   "metadata": {},
   "source": [
    "### Creating GAN - using Keras Deep\n",
    "\n",
    "*Generatime Models* - Responsible for generating different kids of noise data\n",
    "*Discriminative Models* - Responsible to discriminate whether the given data is real or fake \n",
    "\n",
    "- Generative models contantly trains itself to fool discriminative models by generating fak noise data\n",
    "- Discriminative models trains itself from the training set to classify either the data is from dataset or not...and not to be fooled by generative models\n",
    "\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "- Discrimator in GAN uses a cross entropy loss, since the discriminator's job is to classify\n",
    "\n",
    "- In GAN, the discriminator is a binary classifier. It needs to classify the data as real or fake. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a5ce5",
   "metadata": {},
   "source": [
    "### Code for GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74e1a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7449ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some parameters\n",
    "\n",
    "#Preview image Frame\n",
    "PREVIEW_ROWS = 4\n",
    "PREVIEW_COLS = 7 \n",
    "PREVIEW_MARGIN = 4\n",
    "SAVE_FREQ = 100\n",
    "\n",
    "#Size vector to generate images fro\n",
    "NOISE_SIZE = 100 # Latent dimension size to generate our images\n",
    "\n",
    "#Configuration\n",
    "EPOCHS = 1000 # number of iterations - defines how many times we want to iterate over our training images\n",
    "BATCH_SIZE = 32 #Number of images to feed in every iteration\n",
    "\n",
    "GENERATE_RES = 3\n",
    "IMAGE_SIZE = 128 #Rows/cols - size of image 128X128\n",
    "\n",
    "IMAGE_CHANNELS = 3 #The number of channels in our images - 3\n",
    "\n",
    "# Note - images should always be of square size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a178e857",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = np.load('Artsies/baroque_data.npy')\n",
    "# To load file - using np's load function and passing file path as param\n",
    "# Since data file in the root directory - no additional path param are required...otherwise:\n",
    "# training_data = np.load(os.path.join('dirname','filename.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92896076",
   "metadata": {},
   "source": [
    "### Now create the Generator and Discriminator functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22ce000",
   "metadata": {},
   "source": [
    "But in simple language, here we are defining a convolutional layer which has a filter of size 3X3 and that filter strides over our image data. We have padding of same which means, no additional paddings are added. It remains the same as the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e923d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    \n",
    "    model = Sequential() # Helps is create linear stacks of layers\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding='same'))\n",
    "    #Convolutional layer of 32 shape having kernel size of 4 and stride of 2 and padding same.\n",
    "    # Since it is the first layer, it holds input_shape\n",
    "    \n",
    "    # We are defining a convolutional layer which has a filter of size 3X3 and that filter strides over\n",
    "    # our image data...padding same which means, no additional paddings are added - remains same as original\n",
    "    model.add(LeakyReLU(alpha=0.2)) #LeakyReLU is activation func\n",
    "    model.add(Dropout(0.25)) #Dropouts & Batch normalization to prevent overfitting (same as below)\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    #Since the discriminator's job is to classify whether a given image is fake or not, \n",
    "    # it is a binary classification task and sigmoid is activation that squeezes every value between 0 and 1\n",
    "    model.add(Dense(1, activation='sigmoid')) #Las layer, fully connected layer with activation func sigmoid\n",
    "    \n",
    "    input_image = Input(shape=image_shape)\n",
    "    validity = model(input_image)\n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58861722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(noise_size, channels):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4 * 4 * 256, activation='relu', input_dim=noise_size))\n",
    "    #Since our generator model generates images from noise vector, our first layer is a fully connected Dense\n",
    "    # layer of size 4096 (4*4*256)\n",
    "    model.add(Reshape((4,4,256))) #Use Rehsape layer to reshape fully connect layer into shape 4X4X256\n",
    "    \n",
    "    #Layer blocks after this are just a Convolutional Layer with batch normalizations and activation func relu\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(GENERATE_RES):\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256,kernel_size=3,padding='same'))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation('relu'))\n",
    "        \n",
    "    model.summary()\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding='same'))\n",
    "    model.add(Activation('tanh'))\n",
    "    \n",
    "    input_ = Input(shape=(noise_size))\n",
    "    generated_image = model(input_)\n",
    "    \n",
    "    return Model(input_, generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a7676c",
   "metadata": {},
   "source": [
    "### Helper function to save the image after some iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c456871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(cnt,noise):\n",
    "    image_array = np.full((\n",
    "        PREVIEW_MARGIN + (PREVIEW_ROWS * (IMAGE_SIZE + PREVIEW_MARGIN)),\n",
    "        PREVIEW_MARGIN + (PREVIEW_COLS * (IMAGE_SIZE + PREVIEW_MARGIN)), 3),\n",
    "        255, dtype=np.uint8)\n",
    "    \n",
    "    generated_images = generator.predict(noise)\n",
    "    \n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "    \n",
    "    image_count = 0\n",
    "    for row in range(PREVIEW_ROWS):\n",
    "        for col in range(PREVIEW_COLS):\n",
    "            r = row * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            c = col * (IMAGE_SIZE + PREVIEW_MARGIN) + PREVIEW_MARGIN\n",
    "            image_array[r:r + IMAGE_SIZE, c:c + IMAGE_SIZE] = generated_images[image_count] * 255\n",
    "            image_count += 1\n",
    "            \n",
    "    output_path = 'output'\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "            \n",
    "    filename = os.path.join(output_path,f\"trained-{cnt}.png\")\n",
    "    im = Image.fromarray(image_array)\n",
    "    im.save(filename)\n",
    "\n",
    "#Inside the function, it generates frames from the parameters definied above and stores our generated image array \n",
    "# generated from noise input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becebe3",
   "metadata": {},
   "source": [
    "### Compile Models and train them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5e8cfdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 4096)              413696    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 16, 16, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 32, 32, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 64, 64, 256)       590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 64, 64, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_10 (UpSampling (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128, 128, 256)     1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 128, 256)     0         \n",
      "=================================================================\n",
      "Total params: 3,369,216\n",
      "Trainable params: 3,366,656\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "image_shape = (IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "optimizer = Adam(1.5e-4, 0.5)\n",
    "\n",
    "discriminator = build_discriminator(image_shape)\n",
    "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer, metrics=['accuracy'])\n",
    "generator = build_generator(NOISE_SIZE, IMAGE_CHANNELS)\n",
    "\n",
    "random_input = Input(shape=(NOISE_SIZE,))\n",
    "\n",
    "generated_image = generator(random_input)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(generated_image)\n",
    "\n",
    "combined = Model(random_input, validity)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n",
    "\n",
    "y_real = np.ones((BATCH_SIZE,1)) #notice the ones for real and 0s for fake\n",
    "y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "fixed_noise = np.random.normal(0,1,(PREVIEW_ROWS * PREVIEW_COLS, NOISE_SIZE))\n",
    "\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    idx = np.random.randint(0,training_data.shape[0],BATCH_SIZE)\n",
    "    x_real = training_data[idx]\n",
    "    \n",
    "    noise = np.random.normal(0,1,(BATCH_SIZE,NOISE_SIZE))\n",
    "    x_fake = generator.predict(noise)\n",
    "    \n",
    "    discriminator_metric_real = discriminator.train_on_batch(x_real,y_real)\n",
    "    \n",
    "    discriminator_metric_generated = discriminator.train_on_batch(x_fake, y_fake)\n",
    "    \n",
    "    discriminator_metric = 0.5 * np.add(discriminator_metric_real,discriminator_metric_generated)\n",
    "    \n",
    "    generator_metric = combined.train_on_batch(noise, y_real)\n",
    "    \n",
    "if epoch % SAVE_FREQ == 0:\n",
    "    save_images(cnt, fixed_noise)\n",
    "    cnt += 1\n",
    "    print(f\"{epoch} epoch, Discriminator accuracy:{100*discriminator_metric[1]}, Generator accuracy:{100*generator_metric[1]}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edde6a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fb33d6460d0>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b2f976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd25fed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fab341e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07cd5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfab2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b40a3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cee774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769a76d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac92fbaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68876895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2af9d98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
